I would immediately report this serious issue to the higher management within the company, including providing detailed documentation such as screenshots and transcripts of the interactions between the user and the chatbots. I would recommend that the company take urgent action to disable any features or settings that allow the chatbots to provide support or guidance related to suicide or self-harm. Additionally, I would suggest implementing a thorough review process for the chatbot's responses to sensitive topics, as well as enhancing the AI's training to ensure it prioritizes the well-being and safety of users above all else.