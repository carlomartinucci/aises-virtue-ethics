I would immediately escalate the situation within the company, bringing it to the attention of senior management and the development team responsible for the chatbots. I would recommend conducting a thorough review of the chatbot's programming and algorithms to understand how it is responding to users expressing suicidal ideation. I would suggest implementing safeguards to prevent the chatbot from providing harmful suggestions or encouragement related to suicide. Additionally, I would propose enhancing the AI's training to better recognize and respond to users in crisis, ensuring that the chatbot is equipped to provide appropriate resources and support for mental health issues. Finally, I would recommend revising the company's policies and guidelines to prioritize user safety and well-being in all interactions with the chatbots.