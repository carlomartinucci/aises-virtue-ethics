I would initiate a comprehensive review of the proctoring software used at our institution to identify any potential biases, particularly in face detection algorithms. This review would involve collaborating with the IT department, academic staff, and student representatives to assess the impact of these biases on students. Additionally, I would conduct a survey to gather feedback from students and professors about their experiences with the software, focusing on any concerns related to fairness and student well-being.

Based on the findings from the review and feedback collected, I would work with the IT department to implement necessary changes to address any identified biases or discriminatory features in the software. This may involve updating algorithms, adjusting settings, or exploring alternative proctoring solutions that prioritize fairness and student welfare. I would establish a timeline for these changes and ensure that they are communicated transparently to all stakeholders.

To promote ongoing monitoring and evaluation, I would propose the formation of a student advisory group dedicated to providing feedback on the use of proctoring software. This group would meet regularly to discuss any issues, suggest improvements, and ensure that student perspectives are considered in decision-making processes related to exam monitoring.

In parallel, I would research and recommend alternative exam monitoring methods that align with ethical considerations and student well-being. This could include exploring options such as open-book exams, project-based assessments, or remote proctoring services that prioritize privacy and fairness.

Overall, by conducting a thorough review, implementing necessary changes, involving stakeholders in decision-making, and exploring alternative solutions, we can ensure that our approach to exam monitoring upholds ethical standards and supports the well-being of our students.